{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU4ExnoPNZ3A",
        "outputId": "d3ab0776-972e-44ca-8055-23fb271f7449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.90)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.12/dist-packages (0.5.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision matplotlib scikit-learn opencv-python imutils\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imutils import paths\n",
        "from lab_2_helpers import *\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "M9H_2oaDN4Pa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_chars(image):\n",
        "    \"\"\" Find contours and extract characters inside each CAPTCHA. \"\"\"\n",
        "    image_bw = cv2.threshold(\n",
        "        image, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU\n",
        "    )[1]\n",
        "\n",
        "    contours = cv2.findContours(\n",
        "        image_bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        "    )[0]\n",
        "\n",
        "    char_regions = []\n",
        "\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "        if w / h > 1.25:\n",
        "            half = int(w / 2)\n",
        "            char_regions.append((x, y, half, h))\n",
        "            char_regions.append((x + half, y, half, h))\n",
        "        else:\n",
        "            char_regions.append((x, y, w, h))\n",
        "\n",
        "    if len(char_regions) != 4:\n",
        "        return None\n",
        "\n",
        "    char_regions.sort(key=lambda x: x[0])\n",
        "\n",
        "    chars = []\n",
        "    for x, y, w, h in char_regions:\n",
        "        chars.append(image[y-2:y+h+2, x-2:x+w+2])\n",
        "\n",
        "    return chars\n"
      ],
      "metadata": {
        "id": "CJTpV7TiPnTf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf captcha-images.tar.xz\n"
      ],
      "metadata": {
        "id": "l8ZCRxcwN8gW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_transform_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    padded = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n",
        "    return padded\n",
        "\n",
        "CAPTCHA_IMAGE_FOLDER = \"./captcha-images\"\n",
        "captcha_image_paths = list(paths.list_images(CAPTCHA_IMAGE_FOLDER))\n",
        "captcha_images = [load_transform_image(p) for p in captcha_image_paths]\n",
        "captcha_texts = [os.path.splitext(os.path.basename(p))[0] for p in captcha_image_paths]\n"
      ],
      "metadata": {
        "id": "B8ioWXpCN9w4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captcha_images_tv, captcha_images_test, captcha_texts_tv, captcha_texts_test = train_test_split(\n",
        "    captcha_images, captcha_texts, test_size=0.2, random_state=31528476\n",
        ")\n"
      ],
      "metadata": {
        "id": "beR2INw3OFxA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_feature(image):\n",
        "    image = resize_to_fit(image, 20, 20)\n",
        "    image = image.astype(\"float32\") / 255.0\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "Mkpim0cmOIA5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = []\n",
        "labels = []\n",
        "\n",
        "for img, text in zip(captcha_images_tv, captcha_texts_tv):\n",
        "    chars = extract_chars(img)\n",
        "    if chars is None:\n",
        "        continue\n",
        "    for c_img, c in zip(chars, text):\n",
        "        features.append(make_feature(c_img))\n",
        "        labels.append(c)\n",
        "\n",
        "features = np.array(features)\n",
        "labels = np.array(labels)\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "labels_oh = lb.fit_transform(labels)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    features, labels_oh, test_size=0.25, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "vXIWh0SmOMEc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CharDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X).unsqueeze(1)\n",
        "        self.y = torch.tensor(y).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_ds = CharDataset(X_train, y_train)\n",
        "val_ds = CharDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=32)\n"
      ],
      "metadata": {
        "id": "eZ1ibxTdOQ2B"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 20, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(20, 50, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(5*5*50, 500),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(500, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(self.conv(x))\n",
        "\n",
        "model = CNN(len(lb.classes_))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n"
      ],
      "metadata": {
        "id": "q1k14ysGOSz9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    for X, y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(X)\n",
        "        loss = criterion(preds, torch.argmax(y, dim=1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/10 complete\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTQn5Ls7OUit",
        "outputId": "968ba0d2-b9dd-4ca3-8072-3f397cd49eaf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 complete\n",
            "Epoch 2/10 complete\n",
            "Epoch 3/10 complete\n",
            "Epoch 4/10 complete\n",
            "Epoch 5/10 complete\n",
            "Epoch 6/10 complete\n",
            "Epoch 7/10 complete\n",
            "Epoch 8/10 complete\n",
            "Epoch 9/10 complete\n",
            "Epoch 10/10 complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X, y in val_loader:\n",
        "        preds = model(X)\n",
        "        predicted = torch.argmax(preds, dim=1)\n",
        "        actual = torch.argmax(y, dim=1)\n",
        "        correct += (predicted == actual).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "print(\"Validation accuracy:\", correct / total)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2v47cUVOWQw",
        "outputId": "7c7a65b3-6104-410c-9cba-f353f8140d95"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.9887892376681614\n"
          ]
        }
      ]
    }
  ]
}